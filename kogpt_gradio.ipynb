{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kogpt_gradio.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNy70/egEeNcA7rPrsMw+4g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsnam95/class2022Spring/blob/main/kogpt_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8hvVch8ffv2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  pad_token_id=tokenizer.eos_token_id,\n",
        "  torch_dtype='auto', low_cpu_mem_usage=True\n",
        ").to(device='cuda', non_blocking=True)\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '인간처럼 생각하고, 행동하는 \\'지능\\'을 통해 인류가 이제까지 풀지 못했던'\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.8, max_length=64)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)  # print: 인간처럼 생각하고, 행동하는 '지능'을 통해 인류가 이제까지 풀지 못했던 문제의 해답을 찾을 수 있을 것이다. 과학기술이 고도로 발달한 21세기를 살아갈 우리 아이들에게 가장 필요한 것은 사고력 훈련이다. 사고력 훈련을 통해, 세상\n"
      ],
      "metadata": {
        "id": "wBR7s7X2s-u2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}